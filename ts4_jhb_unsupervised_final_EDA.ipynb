{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Recommender Systems\n\n**EDSA 2020: Predict 7 - Unsupervised Learning**\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://raw.githubusercontent.com/Tiroamodimo/tikitaka_unsupervised_project_Repo/master/Notebook_cover_photo.jpg?token=AGIEGQ2SA2OQXDS6RIZSHJK7DUBXC\" width = \"100%\" align = \"left\" />","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Contributors - TS4_JHB\n* Lebogang Lamola (Team Captain)\n* Jagannath Chetty\n* Akhona Stafane\n* Abel Marumo\n* Letlhogile Mothoagae\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Contents\n* [Introduction](#intro)\n* [Library Imports](#libraries)\n* [Data Imports](#data)\n* [Exploratory Data Analysis](#eda)\n* [Data Cleaning](#data_clean)\n* [Feature Engineering](#feat_eng)\n* [Recommender Systems](#rec_sys)\n    * [Content-Based Recommender System](#cb_rec)\n    * [Collaborative Filtering Recommender System](#cf_rec)\n* [Conclusion](#conclusion)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id=\"intro\"></a>\n# Introduction","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"libraries\"></a>\n\n# Library Imports","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Let's install libraries that don't normally come with cloud-based kernels","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install comet_ml","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In order to deploy our model experiments to the team's [comet repository](https://www.comet.ml/tiroamodimo/jhb-ts4-unsupervised/view/new), we'll instantiate an `Experiment` intance before importing other libraries","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# # import comet_ml\n# from comet_ml import Experiment\n# # Add the following code anywhere in your machine learning file\n# experiment = Experiment(api_key=\"quY9CXKJTLd4wCLNuIQqCuVGa\",\n#                      project_name=\"jhb-ts4-unsupervised\",\n#                      workspace=\"tiroamodimo\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we can import the other modules we'll be using in the Notebook","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data Analysis libraries\nimport pandas as pd\nimport numpy as np\n\n# Text Data Analysis\nfrom textblob import TextBlob\nfrom wordcloud import WordCloud\n\n# visualisation libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cufflinks as cf\n\n# Styling\n%matplotlib inline\nsns.set(style='whitegrid', palette='muted',\n        rc={'figure.figsize': (15,10)})\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)\n\n# Machine Learning\nimport surprise\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import preprocessing\nfrom sklearn.decomposition import PCA\n\n# sundry imports\nimport os\nfrom timeit import default_timer\nstart = default_timer()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"data\"></a>\n\n# Data Imports","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The Expected data sets are as follows:\n\n* `genome_scores.csv` - a score mapping the strength between movies and tag-related properties. Read more [here](http://files.grouplens.org/papers/tag_genome.pdf)\n* `genome_tags.csv` - user assigned tags for genome-related scores\n* `imdb_data.csv` - Additional movie metadata scraped from IMDB using the links.csv file.\n* `links.csv` - File providing a mapping between a MovieLens ID and associated IMDB and TMDB IDs.\n* `sample_submission.csv` - Sample of the submission format for the hackathon.\n* `tags.csv` - User assigned for the movies within the dataset.\n* `test.csv` - The test split of the dataset. Contains user and movie IDs with no rating data.\n* `train.csv` - The training split of the dataset. Contains user and movie IDs with associated rating data.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# List all data files\nbasepath = '../input/edsa-recommender-system-predict/'\nfor entry in os.listdir(basepath):\n    if os.path.isfile(os.path.join(basepath, entry)):\n        print(entry)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import Training, Testing and Submission Data\ntrain_df = pd.read_csv(basepath + 'train.csv')\ntest_df = pd.read_csv(basepath + 'test.csv')\nsample_submission_df = pd.read_csv(basepath + 'sample_submission.csv')\n\n# User - Movie relationship\ngenome_scores_df = pd.read_csv(basepath + 'genome_scores.csv')\ngenome_tags_df = pd.read_csv(basepath + 'genome_tags.csv')\n\n# Other Data to be explored\nmovies_df = pd.read_csv(basepath + 'movies.csv')\nimdb_data_df = pd.read_csv(basepath + 'imdb_data.csv')\nlinks_df = pd.read_csv(basepath + 'links.csv')\ntags_df = pd.read_csv(basepath + 'tags.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All ratings are contained in the file `train.csv.` Each line of this file after the header row represents one rating of one movie by one user, and has the following format:\n```\nuserId,movieId,rating,timestamp\n```\n\n* The lines within this file are ordered first by userId, then, within user, by movieId.\n* Ratings are made on a 5-star scale, with half-star increments (0.5 stars - 5.0 stars).\n* Timestamps represent seconds since midnight Coordinated Universal Time (UTC) of January 1, 1970.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_df.shape)\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test_df.shape)\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(movies_df.shape)\nsample_submission_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Movie information is contained in the file `movies.csv`. Each line of this file after the header row represents one movie, and has the following format:\n```\nmovieId,title,genres\n```\nMovie titles are entered manually or imported from https://www.themoviedb.org/, and include the year of release in parentheses. Errors and inconsistencies may exist in these titles.\nGenres are a pipe-separated list, and are selected from the following:\n\n* Action\n* Adventure\n* Animation\n* Children's\n* Comedy\n* Crime\n* Documentary\n* Drama\n* Fantasy\n* Film-Noir\n* Horror\n* Musical\n* Mystery\n* Romance\n* Sci-Fi\n* Thriller\n* War\n* Western\n* (no genres listed)","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print(movies_df.shape)\nmovies_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(imdb_data_df.shape)\nimdb_data_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As described in [this article](http://files.grouplens.org/papers/tag_genome.pdf), the tag genome encodes how strongly movies exhibit particular properties represented by tags (atmospheric, thought-provoking, realistic, etc.). The tag genome was computed using a machine learning algorithm on user-contributed content including tags, ratings, and textual reviews.\n\nThe genome is split into two files. The file `genome-scores.csv` contains movie-tag relevance data in the following format:\n```\nmovieId,tagId,relevance\n```","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(genome_tags_df.shape)\ngenome_scores_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The second file, `genome-tags.csv`, provides the tag descriptions for the tag IDs in the genome file, in the following format:\n```\ntagId,tag\n```","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(genome_tags_df.shape)\ngenome_tags_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Identifiers that can be used to link to other sources of movie data are contained in the file `links.csv`. Each line of this file after the header row represents one movie, and has the following format:\n```\nmovieId,imdbId,tmdbId\n```\nmovieId is an identifier for movies used by https://movielens.org. E.g., the movie Toy Story has the link https://movielens.org/movies/1.\n\nimdbId is an identifier for movies used by http://www.imdb.com. E.g., the movie Toy Story has the link http://www.imdb.com/title/tt0114709/.\n\ntmdbId is an identifier for movies used by https://www.themoviedb.org. E.g., the movie Toy Story has the link https://www.themoviedb.org/movie/862.\n\nUse of the resources listed above is subject to the terms of each provider.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(links_df.shape)\nlinks_df.head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All tags are contained in the file `tags.csv`. Each line of this file after the header row represents one tag applied to one movie by one user, and has the following format:\n```\nuserId,movieId,tag,timestamp\n```\n\nThe lines within this file are ordered first by userId, then, within user, by movieId.\n\nTags are user-generated metadata about movies. Each tag is typically a single word or short phrase. The meaning, value, and purpose of a particular tag is determined by each user.\n\nTimestamps represent seconds since midnight Coordinated Universal Time (UTC) of January 1, 1970","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(tags_df.shape)\ntags_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"eda\"></a>\n\n# Exploratory Data Analysis","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Missing Data and Data Types","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"In order to facilitate the identification of missing data and data types, a function, `print_dtypes_missing`, is defined below","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def print_dtypes_null(df):\n    \n    \"\"\"\n    This function takes a dataframe as input and prints out the\n    datatypes and null values datatypes of the dataframe\n    \"\"\"\n    \n    # print data types\n    print('Data type')\n    print(df.info(),'\\n======================')\n    \n    \n    # get number of null values\n    total = df.isnull().sum().sort_values(ascending=False)\n    \n    # get percentage null values\n    percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)*100\n    \n    # create dataframe\n    print('Missing Values')\n    print(pd.concat([total, percent], axis=1, keys=['Total Number Missing', 'Percent Missing']),'\\n======================')\n    \n    # print original dataframe for ease of reading\n    print('Dataset')\n    print(df.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data types and missing values were assessed below","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print_dtypes_null(train_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`train_df` consists of numerical data, _int64_ and _float64_ and has no missing values in any of the columns","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print_dtypes_null(test_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`test_df` consists of numerical data, _int64_, and has no missing values in any of the columns","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print_dtypes_null(genome_scores_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`genome_scores_df` consists of numerical data, _int64_ and _float64_ and has no missing values in any of the columns","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print_dtypes_null(genome_tags_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`genome_tags_df` consists of numerical data, _int64_ and _float64_ and has no missing values in any of the columns","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print_dtypes_null(movies_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`movies_df` consists of numerical data, _int64_ , and and non-numeric data _object_ and has no missing values in any of the columns","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print_dtypes_null(imdb_data_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`imdb_data_df` consists of numerical data, _float64_ and has no 5 columns with missing data ranging from 36% to for `director` to 71% `budget`","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print_dtypes_null(links_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`links_df` consists of numerical data, _int64_ and _float64_ and has 1 column, `tmdbId` with 17% missing data ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print_dtypes_null(tags_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`tags_df` consists of numerical data, _int64_ , and non-numeric data, _object_ ,and has less than 1% missing values for `tag` column","execution_count":null},{"metadata":{"trusted":false},"cell_type":"markdown","source":"**Outcomes From Assessment of Datatypes and Null Values**\n\n1. From the assessment we see that our dataset consists of a combination of _numeric_ and _non-numeric_ data types\n    * in order to implement machine learning, the non-numeric datatypes need to be converted to numeric datatypes.\n2. The `imdb_data_df` dataset is has 36% - 71% missing data across all the columns. This datatset will therefore not be considered going forward in this excercise. In a different context however, the `links_df` dataset would be used to source the missing data from a supplementary dataset. The `links_df` dataset will also not be considered going forward.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove data that will not be considered\ndel imdb_data_df\ndel links_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Assessing The Data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"In order to facilitate the assessment of our data the functions below are defined.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_histogram(df, col):\n\n\n    # Plot the histogram with default number of bins; label your axes\n    _ = plt.hist(df[col])\n    _ = plt.xlabel(col)\n    _ = plt.ylabel('Frequency')\n    \n    plt.savefig(f'Histogram of {col}.png')\n\n    # Show the plot\n    plt.show()\n\n\ndef show_wordcloud(data, col):\n    \n    # define text from data\n    text = ' '.join(data[col].values.astype(str))\n    \n    # generate wordclound\n    wordcloud = WordCloud(max_words=50,\n                          background_color='black',\n                          scale=3,\n                          random_state=4).generate(str(text))\n    \n    # plot wordcloud\n    fig = plt.figure(1, figsize=(15, 15))\n    plt.axis('off')\n        \n    plt.savefig(f'Word cloud of {col}.png')\n    plt.imshow(wordcloud)\n    plt.show()\n\n\ndef ecdf(data):\n    \n    \"\"\"Compute ECDF for a one-dimensional array of measurements.\"\"\"\n    \n    # Number of data points: n\n    n = len(data)\n\n    # x-data for the ECDF: x\n    x = np.sort(data)\n\n    # y-data for the ECDF: y\n    y = np.arange(1, n+1) / n\n\n    return x, y\n\n\ndef plot_ecdf(df, col):\n    \n    \"\"\"plot ECDF for a column, col, in a dataframe, df.\"\"\"\n    \n    # Compute ECDF \n    x, y = ecdf(df[col])\n    \n    # Generate plot\n    _ = plt.plot(x, y, marker='.', linestyle = 'none')\n    \n    # Label axes\n    _ = plt.ylabel('ECDF')\n    _ = plt.xlabel(f'{col}')\n    \n    plt.savefig(f'ecdf of {col}.png')\n    \n    # display\n    plt.show","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Assessing the `train_df` data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 10 000 038 records in the train_df dataset. However there are 162 541 usersIDs with 48 213 movies that interacted with them. There are 10 unique ratings that were made and 8 795 101 different times.\n\nIt was assumed that people view different movies at different times for reasons that have little or nothing to do with _movies_ they like. For this reason, The `timestamp` data will not be assessed going forward in this exercise\n\nThe `rating` data was be explored below","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['rating'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"make_histogram(train_df, 'rating')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Most users rated movies with a 4 followed by 3 an and 5 respectively.\n* On average users rated movies with 3.5\n* 0.5 was the least frequent rating observed\n* in general ratings below 3 were less frequent.\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Assessing the `movies_df` data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"movies_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"movies_df.nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* There are 62 423 records in the `movies_df` data and 62 423 unique movie Ids. There are 62 325 unique movie titles. This suggests that 98 Movie titles are duplicated. There are 1639 different combinations of genres for the various movies","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"show_wordcloud(movies_df, 'genres')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* 'no genres', 'genres listed', 'Comedy Drama' and 'Drama Romance' are the most common genre type, closely followed by 'Thriller Comedy', 'Thriller Drama' and 'Romance Comedy'\n* The `genres` data includes a combination of different genres, this can normalised to 1NF to make the data easier to analyse\n* The `titles` column includes the year that the movies was released, which can be extracted.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Assessing `genome_tags_df` data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"genome_tags_df.describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"genome_tags_df.nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 1128 unique values under `tag`. Let's have a closer look at the most common words","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"show_wordcloud(genome_tags_df, 'tag')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* The most common words under the `tag` data are 'war' and 'good', followed closely by 'movie' and 'comedy'","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Assessing the `genome_scores_df` data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"genome_scores_df.describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"genome_scores_df.nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* 13 816 movies have have tags with an associated `relevance` score.\n\nThe `relevance` was investigated further below","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"make_histogram(genome_scores_df, 'relevance')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_ecdf(genome_scores_df, 'relevance')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* More than 80% of the tags have a relevance of less than 0.2 for each movie\n* The `genome_tags_df` and `genome_scores_df` provide interesting meta-data about movies. However because only 13 816 out of 62 423 (22%)\n* The abovemened datasets were not be considered futher in this exercise for the reason stated above","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"del genome_tags_df\ndel genome_scores_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Assessing the `tags_df` data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"tags_df.describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tags_df.nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* The `timestamp data` will not be assessed in this dataset for this exerceised for the same reason it was not assessed in the `train_df` data\n\nthe `tag` data was explored further below","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"show_wordcloud(tags_df, 'tag')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* there are 45 251 movies out of 62 423 (72%) with associated tags\n* This data may be useful in describing 72% of the movies data, therefore it will be kept.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id=\"data_clean\"></a>\n# Data Cleaning","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The previous assessment assisted in ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"feat_eng\"></a>\n\n# Feature Engineering","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"# get the year\nmovies_df['year'] = movies_df.title.str.extract(\"\\((\\d{4})\\)\", expand=True)\n\n# remove the year from the title\nmovies_df['title'] = movies_df['title'].apply(lambda x: ' '.join(re.findall(r'[^ (\\d)]+',x)))\n\n# get the number of genres\nmovies_df['genre_count'] = movies_df['genres'].apply(lambda x: x.count('|') + 1)\n\n# get the polarity of the title\nmovies_df['title_polarity'] = movies_df['title'].apply(lambda x: TextBlob(x).sentiment.polarity)\n\n# get the subjectivity of the title\nmovies_df['title_subjectivity'] = movies_df['title'].apply(lambda x: TextBlob(x).sentiment.subjectivity)\n\n\nmovies_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"rec_sys\"></a>\n\n# Recommender Systems","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Now that the data is prepared, the machine learning experiments will follow. The functions below are defined to enable experiments to be deployed to the team's [comet repository](https://www.comet.ml/tiroamodimo/jhb-ts4-unsupervised/view/new)","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"def remove_unchanged_params(params_dict, used_params_list=None):\n    \n    \"\"\"\n    This function takes a dictionary of parameters and a list of used parameters\n    as inputs and returns a dictionary of parameters that are in the list of\n    used parameters.\n    \"\"\"\n\n    # check if a list of parameters was specified\n    if used_params_list == None:\n\n      # if not return the original dictionary\n      return {'params_used': 'default'}\n\n    # initialise a new dictionary of parameters\n    new_params_dict = {'params_used': 'custom'}\n\n    # for each parameter in params_dict\n    for param in params_dict.keys():\n\n      # if a parameter is in used_params_list\n      if param in used_params_list:\n\n          # add that parameter's entry to the new dictionary of parameters\n          new_params_dict[param] = params_dict[param]\n\n    return new_params_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def add_model_type(params_dict,model_type='Not Specified'):\n\n    \"\"\"\n    This function takes a dictionary of parameters as inputs\n    and returns a dictionary of parameters that includes the specified\n    model_type.\n    \"\"\"\n\n    # add model_type parameter to the dictionary\n    params_dict['model_type'] = model_type\n\n    return params_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def make_comet_model_params(model_params, model_name, used_params_list=None):\n\n    \"\"\"\n    This function takes a dictionary of model parameters, a string of the model type and list of\n    parameters as inputs and returns a dictionary of parameters of used in the\n    model for comet experiment logging.\n    \"\"\"\n\n    # get parameters that were were used\n    new_params_dict = remove_unchanged_params(model_params,\n                                            used_params_list)\n\n    # add model_type to dictionary of parameters\n    new_params_dict = add_model_type(new_params_dict,model_name)\n\n    return new_params_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def deploy_comet(experiment, metrics, parameters=None):\n    \"\"\"\n    This function takes a comet experiment object, a dictionary of model\n    parameters and a dictionary of model test results as inputs and uploads\n    the experiment to comet.\n    \"\"\"\n\n    # Log our parameters\n    if parameters != None:\n        print('logging parameters...')\n        experiment.log_parameters(parameters)\n\n    # log model performace\n    print('logging metric...')\n    experiment.log_metrics(metrics)\n\n    print('ending experiment...')\n    # end experiment\n    experiment.end()\n\n    # display experiment\n    experiment.display()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"cb_rec\"></a>\n\n## Content-Based Recommender System","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"cf_rec\"></a>\n\n## Collaborative Filtering Recommender System","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"conclusion\"></a>\n\n# Conclusion","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}